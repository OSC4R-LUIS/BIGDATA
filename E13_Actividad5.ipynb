{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7ba9d8",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## **Curso:** Análisis de grandes volúmenes de datos\n",
    "\n",
    "## **Tecnológico de Monterrey**\n",
    "\n",
    "## **Actividad 5:**  Visualización de resultados\n",
    "## **Equipo :** 13\n",
    "## **Integrantes :** \n",
    "- Kevin Balderas Sánchez – A01795149\n",
    "- Alan Jasso Arenas – A01383272\n",
    "- José Florencio Maguey Peralta – A01796727\n",
    "- Oscar Luis Guadarrama Jiménez – A01796245\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95fba8",
   "metadata": {},
   "source": [
    "## Inicio y Preparación del Entorno\n",
    "\n",
    "En esta sección se realiza la configuración inicial para la ejecución del experimento. Se importan las librerías necesarias, se crea la sesión de Spark y se carga el dataset `muestra_M_indexado.csv`, generado previamente en la Actividad 4. Este dataset corresponde a una muestra representativa de la población original, ya depurada, caracterizada e indexada.\n",
    "\n",
    "Finalmente, se realiza una revisión preliminar de su estructura para asegurar que se encuentra en condiciones óptimas para el proceso de validación cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470154f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# SESIÓN SPARK Y CONFIGURACIÓN\n",
    "# -------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -------------------------\n",
    "# TRANSFORMACIONES EN SPARK\n",
    "# -------------------------\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, isnan, count, round, regexp_replace, expr, lit,\n",
    "    percentile_approx, first, sum, skewness, log1p\n",
    ")\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# -------------------------\n",
    "# PREPROCESAMIENTO\n",
    "# -------------------------\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# -------------------------\n",
    "# MODELOS SUPERVISADOS\n",
    "# -------------------------\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# -------------------------\n",
    "# EVALUACIÓN DE MODELOS\n",
    "# -------------------------\n",
    "from pyspark.ml.evaluation import (\n",
    "    MulticlassClassificationEvaluator,\n",
    "    BinaryClassificationEvaluator\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# ANÁLISIS Y VISUALIZACIÓN\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------\n",
    "# LIBRERÍAS ADICIONALES DE SKLEARN\n",
    "# -------------------------\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775d9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Entrenamiento Optimizado\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"48g\") \\\n",
    "    .config(\"spark.executor.memory\", \"48g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"64\") \\\n",
    "    .config(\"spark.default.parallelism\", \"64\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4dec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://OscarGuadarrama:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Entrenamiento Optimizado</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x132e323b200>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3de630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "|loan_amnt|int_rate|      installment|grade|emp_length|home_ownership|        annual_inc|verification_status|loan_status|     purpose|               dti|    inq_last_6mths|          open_acc|        revol_bal|revol_util|         total_acc|        out_prncp|      total_pymnt|   total_rec_prncp|     total_rec_int|  last_pymnt_amnt|       tot_cur_bal|  total_rev_hi_lim|acc_open_past_24mths|      avg_cur_bal|bc_util|          mort_acc|mths_since_recent_bc|mths_since_recent_inq|    num_actv_bc_tl|   num_actv_rev_tl|       num_bc_sats|         num_il_tl|num_rev_tl_bal_gt_0|          num_sats|num_tl_op_past_12m|   pct_tl_nvr_dlq|percent_bc_gt_75|   tot_hi_cred_lim| total_bal_ex_mort|total_il_high_credit_limit|\n",
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "|  22400.0|   16.14|6.305179796606579|    C| 10+ years|           OWN|10.933124826700707|    Source Verified|          0|debt_related| 2.968874819384108|               0.0| 2.772588722239781|9.514584532726943|      38.2|3.1354942159291497|  9.9945614994355|6.969480471419075| 6.203628037579029| 6.345864404999986|6.305179796606579|12.287988981480897|10.477316144080852|  1.0986122886681096|9.579971027075132|   46.6| 1.791759469228055|  3.6109179126442243|    1.791759469228055| 1.791759469228055|2.0794415416798357|2.1972245773362196| 1.791759469228055| 2.0794415416798357| 2.772588722239781|1.0986122886681096| 4.56954300834494|            25.0|12.443276880492718|10.375707473990893|        10.058994455134526|\n",
      "|  21000.0|   15.02|6.216226787637648|    C|   5 years|           OWN|10.819798284210286|    Source Verified|          0|debt_related|               0.0|               0.0| 1.791759469228055|              0.0|       0.0|2.8903717578961645|9.929350212061856|6.881760318705052| 6.169380580485503| 6.209495049035369|6.216226787637648| 9.729312720877942| 7.741099090035366|  1.3862943611198906|8.119993827725105|    0.0|               0.0|   2.995732273553991|   2.3978952727983707|               0.0|               0.0|0.6931471805599453|1.9459101490553132|                0.0| 1.791759469228055|1.0986122886681096| 4.61512051684126|             0.0|10.012386799492118| 9.729312720877942|          9.90353755128617|\n",
      "|  13000.0|    7.02|5.997769628242576|    A|   8 years|           OWN|10.463131911491967|    Source Verified|          0|debt_related|3.6130777406976544|               0.0| 2.772588722239781| 9.33300038471207|      19.4|  3.58351893845611| 9.42124938562205|6.680176908377815| 6.482893261263241|4.9670316566141235|5.997769628242576|10.681458301911103|10.971657815702502|  0.6931471805599453|8.042699496897637|   23.8|0.6931471805599453|   3.258096538021482|    1.791759469228055|1.9459101490553132|2.4849066497880004|2.0794415416798357|2.4849066497880004| 2.4849066497880004| 2.772588722239781|0.6931471805599453| 4.61512051684126|             0.0|11.447842795810972|10.681458301911103|        10.477259806052668|\n",
      "|  21600.0|   16.91|6.285588327139239|    C| 10+ years|           OWN|11.468231400319343|    Source Verified|          0|debt_related|3.1363634032937364|1.3862943611198906|2.5649493574615367|9.412627941411015|      27.4|3.5263605246161616|9.958638397000977|6.949012378830338|6.1464577290734805| 6.356211821937587|6.285588327139239|11.402396058025152|10.707751151716078|   2.639057329615259|8.917578753781104|   27.6|1.3862943611198906|  1.0986122886681096|   0.6931471805599453| 1.791759469228055|1.9459101490553132|2.0794415416798357|2.1972245773362196| 1.9459101490553132|2.5649493574615367| 1.791759469228055|4.574710978503383|             0.0|11.772994790386107|11.402396058025152|        11.350430064607407|\n",
      "|  15000.0|    6.46|6.132247706993426|    A| 10+ years|           OWN|11.775266652248366|    Source Verified|          0|debt_related|2.6602595372658615|               0.0|  2.70805020110221|9.726810038127258|      42.0| 3.332204510175204|9.563880407219427|6.788566255387776|6.6339498128656995| 4.853279483320049|6.132247706993426|11.060918912426148|10.594156665220533|  0.6931471805599453|8.496173824192162|   47.8|               0.0|    4.31748811353631|    1.791759469228055|1.6094379124341003|2.0794415416798357| 1.791759469228055|2.0794415416798357| 2.0794415416798357|  2.70805020110221|0.6931471805599453|4.268297869345539|            20.0|11.604273259429505|11.060918912426148|        11.151453318547691|\n",
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leer el CSV\n",
    "muestra_M = spark.read.csv(\"muestra_M.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Verifica la carga\n",
    "muestra_M.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec078fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- loan_status: integer (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- dti: double (nullable = true)\n",
      " |-- inq_last_6mths: double (nullable = true)\n",
      " |-- open_acc: double (nullable = true)\n",
      " |-- revol_bal: double (nullable = true)\n",
      " |-- revol_util: double (nullable = true)\n",
      " |-- total_acc: double (nullable = true)\n",
      " |-- out_prncp: double (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- total_rec_prncp: double (nullable = true)\n",
      " |-- total_rec_int: double (nullable = true)\n",
      " |-- last_pymnt_amnt: double (nullable = true)\n",
      " |-- tot_cur_bal: double (nullable = true)\n",
      " |-- total_rev_hi_lim: double (nullable = true)\n",
      " |-- acc_open_past_24mths: double (nullable = true)\n",
      " |-- avg_cur_bal: double (nullable = true)\n",
      " |-- bc_util: double (nullable = true)\n",
      " |-- mort_acc: double (nullable = true)\n",
      " |-- mths_since_recent_bc: double (nullable = true)\n",
      " |-- mths_since_recent_inq: double (nullable = true)\n",
      " |-- num_actv_bc_tl: double (nullable = true)\n",
      " |-- num_actv_rev_tl: double (nullable = true)\n",
      " |-- num_bc_sats: double (nullable = true)\n",
      " |-- num_il_tl: double (nullable = true)\n",
      " |-- num_rev_tl_bal_gt_0: double (nullable = true)\n",
      " |-- num_sats: double (nullable = true)\n",
      " |-- num_tl_op_past_12m: double (nullable = true)\n",
      " |-- pct_tl_nvr_dlq: double (nullable = true)\n",
      " |-- percent_bc_gt_75: double (nullable = true)\n",
      " |-- tot_hi_cred_lim: double (nullable = true)\n",
      " |-- total_bal_ex_mort: double (nullable = true)\n",
      " |-- total_il_high_credit_limit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muestra_M.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db29674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero total de registros: 337413\n"
     ]
    }
   ],
   "source": [
    "reg = muestra_M.count()\n",
    "\n",
    "print(\"numero total de registros:\", reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac59d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "|loan_amnt|int_rate|installment|grade|emp_length|home_ownership|annual_inc|verification_status|loan_status|purpose|dti|inq_last_6mths|open_acc|revol_bal|revol_util|total_acc|out_prncp|total_pymnt|total_rec_prncp|total_rec_int|last_pymnt_amnt|tot_cur_bal|total_rev_hi_lim|acc_open_past_24mths|avg_cur_bal|bc_util|mort_acc|mths_since_recent_bc|mths_since_recent_inq|num_actv_bc_tl|num_actv_rev_tl|num_bc_sats|num_il_tl|num_rev_tl_bal_gt_0|num_sats|num_tl_op_past_12m|pct_tl_nvr_dlq|percent_bc_gt_75|tot_hi_cred_lim|total_bal_ex_mort|total_il_high_credit_limit|\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "|0        |0       |0          |0    |0         |0             |0         |0                  |0          |0      |0  |0             |0       |0        |0         |0        |0        |0          |0              |0            |0              |0          |0               |0                   |0          |0      |0       |0                   |0                    |0             |0              |0          |0        |0                  |0       |0                 |0             |0               |0              |0                |0                         |\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver cuántos valores nulos hay por columna \n",
    "print(\"Valores nulos por columna:\")\n",
    "muestra_M.select([count(when(col(c).isNull(), c)).alias(c) for c in muestra_M.columns]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c2a7c",
   "metadata": {},
   "source": [
    "## 1. Proceso de Validación Cruzada\n",
    "\n",
    "Para evaluar la estabilidad y capacidad de generalización del modelo de clasificación entrenado, se implementó una estrategia de validación cruzada utilizando el enfoque k-fold estratificado. Este método divide la muestra representativa M en k subconjuntos del mismo tamaño, manteniendo la proporción de clases en la variable objetivo (loan_status).\n",
    "\n",
    "En este proyecto se seleccionó un valor de k = 5, ya que la muestra contiene aproximadamente 337,413 registros, con una distribución de clases claramente desbalanceada, aunque aún suficientemente representativa:\n",
    "\n",
    "|loan_status|\tcantidad|\n",
    "|-----------|-----------|\n",
    "|0          |\t293,438 |\n",
    "|1\t        |   43,975  |\n",
    "\n",
    "\n",
    "Esto representa aproximadamente un 87% de clase 0 y un 13% de clase 1, por lo que se justifica el uso de una validación cruzada estratificada, que permita conservar esta proporción en cada fold.\n",
    "\n",
    "La elección de k=5 permite:\n",
    "\n",
    "- Garantizar que cada fold contenga suficientes datos para representar el comportamiento de ambas clases.\n",
    "\n",
    "- Reducir la varianza de las métricas frente a una validación simple (train/test split).\n",
    "\n",
    "- Minimizar el riesgo de sobreajuste al evaluar el modelo en múltiples subconjuntos independientes.\n",
    "\n",
    "- Mantener el costo computacional dentro de márgenes razonables, dado el volumen de datos.\n",
    "\n",
    "Durante esta validación cruzada, se utilizará el modelo que reportó mejor desempeño en la Actividad 4 (Random Forest Classifier), conservando las variables de caracterización utilizadas para construir la muestra M.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d465769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|loan_status| count|\n",
      "+-----------+------+\n",
      "|          0|293438|\n",
      "|          1| 43975|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la distribución de la variable objetivo\n",
    "muestra_M.groupBy('loan_status').count().orderBy(\"count\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74885a7",
   "metadata": {},
   "source": [
    "## 2. Construcción de los k-folds\n",
    "\n",
    "Para construir los pliegues requeridos en la validación cruzada, se utilizó la técnica de StratifiedKFold de la biblioteca scikit-learn. Este método garantiza que cada fold conserve una proporción similar de clases en la variable objetivo loan_status, lo cual es esencial considerando el desbalance observado entre las clases.\n",
    "\n",
    "Se dividió el dataset en 5 folds, asignando a cada registro una etiqueta numérica del 0 al 4 en una nueva columna llamada fold. Esta columna permite controlar qué subconjunto se usará como conjunto de validación en cada iteración del entrenamiento, asegurando que todos los datos sean utilizados tanto para entrenamiento como para prueba a lo largo del proceso.\n",
    "\n",
    "La distribución final se verificó con un conteo cruzado entre fold y loan_status, confirmando la uniformidad del muestreo estratificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c234501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = muestra_M.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc91a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de folds\n",
    "k = 5\n",
    "\n",
    "# Inicializar la columna\n",
    "df_pd[\"fold\"] = -1\n",
    "\n",
    "# Inicializar el objeto StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\n",
    "# Asignar folds\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X=df_pd, y=df_pd[\"loan_status\"])):\n",
    "    df_pd.loc[val_idx, \"fold\"] = fold\n",
    "    \n",
    "df_pd.to_csv('muestra_M_fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9f206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  loan_status\n",
      "0     0              58688\n",
      "      1               8795\n",
      "1     0              58688\n",
      "      1               8795\n",
      "2     0              58688\n",
      "      1               8795\n",
      "3     0              58687\n",
      "      1               8795\n",
      "4     0              58687\n",
      "      1               8795\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_pd.groupby([\"fold\", \"loan_status\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8085dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_folds =  spark.read.csv(\"muestra_M_fold.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2725260",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "\n",
    "En esta etapa se realizó el proceso de entrenamiento del modelo **Random Forest Classifier**, considerado el mejor modelo evaluado en la Actividad 4.\n",
    "\n",
    "El entrenamiento se repitió cinco veces, usando la estrategia de validación cruzada `k-fold` con `k=5`, donde en cada iteración se utilizaron cuatro folds como conjunto de entrenamiento y el restante como conjunto de prueba.\n",
    "\n",
    "Como métrica principal de evaluación se utilizó el **AUC (Área bajo la Curva ROC)**, ya que permite medir la capacidad del modelo para distinguir entre clases, especialmente útil en datasets desbalanceados.\n",
    "\n",
    "Los resultados obtenidos en cada fold fueron almacenados para su posterior análisis visual y discusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0989354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detectar columnas categóricas\n",
    "columnas_categoricas = [c for c, dtype in df_folds.dtypes if dtype == 'string' and c not in ['fold', 'loan_status']]\n",
    "\n",
    "# 2. Indexar y codificar\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\", handleInvalid=\"keep\") for col in columnas_categoricas]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_idx\", outputCol=col + \"_vec\") for col in columnas_categoricas]\n",
    "\n",
    "# 3. Crear lista de columnas finales para ensamblar (numéricas + codificadas)\n",
    "columnas_numericas = [c for c in df_folds.columns if c not in columnas_categoricas + ['fold', 'loan_status']]\n",
    "columnas_finales = columnas_numericas + [col + \"_vec\" for col in columnas_categoricas]\n",
    "target = \"loan_status\"\n",
    "\n",
    "# 4. Ensamblar features\n",
    "assembler = VectorAssembler(inputCols=columnas_finales, outputCol=\"features\")\n",
    "\n",
    "# 5. Construir Pipeline de preprocesamiento\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "# 6. Ejecutar pipeline\n",
    "df_folds_as = pipeline.fit(df_folds).transform(df_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c9a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluadores\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=target, rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"weightedRecall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07fe7882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Fold 0\n",
      "Fold 0 AUC: 0.9660 | Accuracy: 0.9556 | F1: 0.9516 | Precision: 0.9577 | Recall: 0.9556| Accuracy_train: 0.9564 | F1_train: 0.9525 | \n",
      "\n",
      "Entrenando Fold 1\n",
      "Fold 1 AUC: 0.9649 | Accuracy: 0.9551 | F1: 0.9511 | Precision: 0.9572 | Recall: 0.9551| Accuracy_train: 0.9565 | F1_train: 0.9527 | \n",
      "\n",
      "Entrenando Fold 2\n",
      "Fold 2 AUC: 0.9658 | Accuracy: 0.9594 | F1: 0.9561 | Precision: 0.9611 | Recall: 0.9594| Accuracy_train: 0.9605 | F1_train: 0.9575 | \n",
      "\n",
      "Entrenando Fold 3\n",
      "Fold 3 AUC: 0.9657 | Accuracy: 0.9567 | F1: 0.9529 | Precision: 0.9587 | Recall: 0.9567| Accuracy_train: 0.9576 | F1_train: 0.9540 | \n",
      "\n",
      "Entrenando Fold 4\n",
      "Fold 4 AUC: 0.9627 | Accuracy: 0.9580 | F1: 0.9544 | Precision: 0.9598 | Recall: 0.9580| Accuracy_train: 0.9610 | F1_train: 0.9580 | \n"
     ]
    }
   ],
   "source": [
    "resultados_folds = []\n",
    "matrices_confusion = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nEntrenando Fold {i}\")\n",
    "    try:\n",
    "        train_df = df_folds_as.filter(col(\"fold\") != i)\n",
    "        test_df = df_folds_as.filter(col(\"fold\") == i)\n",
    "\n",
    "        rf = RandomForestClassifier(\n",
    "            labelCol=target,\n",
    "            featuresCol=\"features\",\n",
    "            numTrees=100,\n",
    "            maxDepth=10,\n",
    "            seed=1\n",
    "        )\n",
    "\n",
    "        modelo = rf.fit(train_df)\n",
    "        pred_train = modelo.transform(train_df)\n",
    "        predicciones = modelo.transform(test_df)\n",
    "\n",
    "        # Calcular métricas\n",
    "        auc = evaluator_auc.evaluate(predicciones)\n",
    "        acc = evaluator_acc.evaluate(predicciones)\n",
    "        f1 = evaluator_f1.evaluate(predicciones)\n",
    "        precision = evaluator_precision.evaluate(predicciones)\n",
    "        recall = evaluator_recall.evaluate(predicciones)\n",
    "        acc_train = evaluator_acc.evaluate(pred_train)\n",
    "        f1_train = evaluator_f1.evaluate(pred_train)\n",
    "\n",
    "        resultados_folds.append({\n",
    "            \"fold\": i,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1\": f1,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"Train_Accuracy\": acc_train,\n",
    "            \"Train_F1\": f1_train\n",
    "        })\n",
    "\n",
    "        # Matriz de confusión\n",
    "        matriz = predicciones.groupBy(target, \"prediction\").count().orderBy(target, \"prediction\")\n",
    "        matrices_confusion.append(matriz)\n",
    "\n",
    "        print(f\"Fold {i} AUC: {auc:.4f} | Accuracy: {acc:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}| Accuracy_train: {acc_train:.4f} | F1_train: {f1_train:.4f} | \")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en Fold {i}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1affdb54",
   "metadata": {},
   "source": [
    "## 4. Visualización de Resultados\n",
    "\n",
    "En esta sección se presentan las visualizaciones generadas a partir de los resultados obtenidos durante la experimentación con validación cruzada. Las métricas evaluadas en cada fold permiten observar la estabilidad del modelo, así como identificar posibles variaciones en su rendimiento.\n",
    "\n",
    "A continuación, se muestran las gráficas más relevantes:\n",
    "\n",
    "- **Boxplot de métricas (Accuracy, F1, Precision, Recall)** por fold.\n",
    "- **Curva ROC promedio** del modelo, tomando los valores de predicción en cada iteración.\n",
    "- **Matriz de confusión consolidada**, sumando los errores de clasificación acumulados.\n",
    "\n",
    "Estas visualizaciones permiten identificar si el modelo presenta inestabilidad, sobreajuste o sesgo hacia alguna de las clases, complementando el análisis numérico realizado anteriormente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Actividad0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
