{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7ba9d8",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## **Curso:** Análisis de grandes volúmenes de datos\n",
    "\n",
    "## **Tecnológico de Monterrey**\n",
    "\n",
    "## **Actividad 5:**  Visualización de resultados\n",
    "## **Equipo :** 13\n",
    "## **Integrantes :** \n",
    "- Kevin Balderas Sánchez – A01795149\n",
    "- Alan Jasso Arenas – A01383272\n",
    "- José Florencio Maguey Peralta – A01796727\n",
    "- Oscar Luis Guadarrama Jiménez – A01796245\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95fba8",
   "metadata": {},
   "source": [
    "## Inicio y Preparación del Entorno\n",
    "\n",
    "En esta sección se realiza la configuración inicial para la ejecución del experimento. Se importan las librerías necesarias, se crea la sesión de Spark y se carga el dataset `muestra_M_indexado.csv`, generado previamente en la Actividad 4. Este dataset corresponde a una muestra representativa de la población original, ya depurada, caracterizada e indexada.\n",
    "\n",
    "Finalmente, se realiza una revisión preliminar de su estructura para asegurar que se encuentra en condiciones óptimas para el proceso de validación cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "470154f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# SESIÓN SPARK Y CONFIGURACIÓN\n",
    "# -------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -------------------------\n",
    "# TRANSFORMACIONES EN SPARK\n",
    "# -------------------------\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, isnan, count, round, regexp_replace, expr, lit,\n",
    "    percentile_approx, first, sum, skewness, log1p\n",
    ")\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# -------------------------\n",
    "# PREPROCESAMIENTO\n",
    "# -------------------------\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# -------------------------\n",
    "# MODELOS SUPERVISADOS\n",
    "# -------------------------\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# -------------------------\n",
    "# EVALUACIÓN DE MODELOS\n",
    "# -------------------------\n",
    "from pyspark.ml.evaluation import (\n",
    "    MulticlassClassificationEvaluator,\n",
    "    BinaryClassificationEvaluator\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# ANÁLISIS Y VISUALIZACIÓN\n",
    "# -------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------\n",
    "# LIBRERÍAS ADICIONALES DE SKLEARN\n",
    "# -------------------------\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "775d9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Entrenamiento Optimizado\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"48g\") \\\n",
    "    .config(\"spark.executor.memory\", \"48g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"64\") \\\n",
    "    .config(\"spark.default.parallelism\", \"64\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd4dec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://OscarGuadarrama:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Entrenamiento Optimizado</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d788771ca0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc3de630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "|loan_amnt|int_rate|      installment|grade|emp_length|home_ownership|        annual_inc|verification_status|loan_status|     purpose|               dti|    inq_last_6mths|          open_acc|        revol_bal|revol_util|         total_acc|        out_prncp|      total_pymnt|   total_rec_prncp|     total_rec_int|  last_pymnt_amnt|       tot_cur_bal|  total_rev_hi_lim|acc_open_past_24mths|      avg_cur_bal|bc_util|          mort_acc|mths_since_recent_bc|mths_since_recent_inq|    num_actv_bc_tl|   num_actv_rev_tl|       num_bc_sats|         num_il_tl|num_rev_tl_bal_gt_0|          num_sats|num_tl_op_past_12m|   pct_tl_nvr_dlq|percent_bc_gt_75|   tot_hi_cred_lim| total_bal_ex_mort|total_il_high_credit_limit|\n",
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "|  22400.0|   16.14|6.305179796606579|    C| 10+ years|           OWN|10.933124826700707|    Source Verified|          0|debt_related| 2.968874819384108|               0.0| 2.772588722239781|9.514584532726943|      38.2|3.1354942159291497|  9.9945614994355|6.969480471419075| 6.203628037579029| 6.345864404999986|6.305179796606579|12.287988981480897|10.477316144080852|  1.0986122886681096|9.579971027075132|   46.6| 1.791759469228055|  3.6109179126442243|    1.791759469228055| 1.791759469228055|2.0794415416798357|2.1972245773362196| 1.791759469228055| 2.0794415416798357| 2.772588722239781|1.0986122886681096| 4.56954300834494|            25.0|12.443276880492718|10.375707473990893|        10.058994455134526|\n",
      "|  21000.0|   15.02|6.216226787637648|    C|   5 years|           OWN|10.819798284210286|    Source Verified|          0|debt_related|               0.0|               0.0| 1.791759469228055|              0.0|       0.0|2.8903717578961645|9.929350212061856|6.881760318705052| 6.169380580485503| 6.209495049035369|6.216226787637648| 9.729312720877942| 7.741099090035366|  1.3862943611198906|8.119993827725105|    0.0|               0.0|   2.995732273553991|   2.3978952727983707|               0.0|               0.0|0.6931471805599453|1.9459101490553132|                0.0| 1.791759469228055|1.0986122886681096| 4.61512051684126|             0.0|10.012386799492118| 9.729312720877942|          9.90353755128617|\n",
      "|  13000.0|    7.02|5.997769628242576|    A|   8 years|           OWN|10.463131911491967|    Source Verified|          0|debt_related|3.6130777406976544|               0.0| 2.772588722239781| 9.33300038471207|      19.4|  3.58351893845611| 9.42124938562205|6.680176908377815| 6.482893261263241|4.9670316566141235|5.997769628242576|10.681458301911103|10.971657815702502|  0.6931471805599453|8.042699496897637|   23.8|0.6931471805599453|   3.258096538021482|    1.791759469228055|1.9459101490553132|2.4849066497880004|2.0794415416798357|2.4849066497880004| 2.4849066497880004| 2.772588722239781|0.6931471805599453| 4.61512051684126|             0.0|11.447842795810972|10.681458301911103|        10.477259806052668|\n",
      "|  21600.0|   16.91|6.285588327139239|    C| 10+ years|           OWN|11.468231400319343|    Source Verified|          0|debt_related|3.1363634032937364|1.3862943611198906|2.5649493574615367|9.412627941411015|      27.4|3.5263605246161616|9.958638397000977|6.949012378830338|6.1464577290734805| 6.356211821937587|6.285588327139239|11.402396058025152|10.707751151716078|   2.639057329615259|8.917578753781104|   27.6|1.3862943611198906|  1.0986122886681096|   0.6931471805599453| 1.791759469228055|1.9459101490553132|2.0794415416798357|2.1972245773362196| 1.9459101490553132|2.5649493574615367| 1.791759469228055|4.574710978503383|             0.0|11.772994790386107|11.402396058025152|        11.350430064607407|\n",
      "|  15000.0|    6.46|6.132247706993426|    A| 10+ years|           OWN|11.775266652248366|    Source Verified|          0|debt_related|2.6602595372658615|               0.0|  2.70805020110221|9.726810038127258|      42.0| 3.332204510175204|9.563880407219427|6.788566255387776|6.6339498128656995| 4.853279483320049|6.132247706993426|11.060918912426148|10.594156665220533|  0.6931471805599453|8.496173824192162|   47.8|               0.0|    4.31748811353631|    1.791759469228055|1.6094379124341003|2.0794415416798357| 1.791759469228055|2.0794415416798357| 2.0794415416798357|  2.70805020110221|0.6931471805599453|4.268297869345539|            20.0|11.604273259429505|11.060918912426148|        11.151453318547691|\n",
      "+---------+--------+-----------------+-----+----------+--------------+------------------+-------------------+-----------+------------+------------------+------------------+------------------+-----------------+----------+------------------+-----------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-----------------+-------+------------------+--------------------+---------------------+------------------+------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+----------------+------------------+------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leer el CSV\n",
    "muestra_M = spark.read.csv(\"muestra_M.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Verifica la carga\n",
    "muestra_M.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec078fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- loan_status: integer (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- dti: double (nullable = true)\n",
      " |-- inq_last_6mths: double (nullable = true)\n",
      " |-- open_acc: double (nullable = true)\n",
      " |-- revol_bal: double (nullable = true)\n",
      " |-- revol_util: double (nullable = true)\n",
      " |-- total_acc: double (nullable = true)\n",
      " |-- out_prncp: double (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- total_rec_prncp: double (nullable = true)\n",
      " |-- total_rec_int: double (nullable = true)\n",
      " |-- last_pymnt_amnt: double (nullable = true)\n",
      " |-- tot_cur_bal: double (nullable = true)\n",
      " |-- total_rev_hi_lim: double (nullable = true)\n",
      " |-- acc_open_past_24mths: double (nullable = true)\n",
      " |-- avg_cur_bal: double (nullable = true)\n",
      " |-- bc_util: double (nullable = true)\n",
      " |-- mort_acc: double (nullable = true)\n",
      " |-- mths_since_recent_bc: double (nullable = true)\n",
      " |-- mths_since_recent_inq: double (nullable = true)\n",
      " |-- num_actv_bc_tl: double (nullable = true)\n",
      " |-- num_actv_rev_tl: double (nullable = true)\n",
      " |-- num_bc_sats: double (nullable = true)\n",
      " |-- num_il_tl: double (nullable = true)\n",
      " |-- num_rev_tl_bal_gt_0: double (nullable = true)\n",
      " |-- num_sats: double (nullable = true)\n",
      " |-- num_tl_op_past_12m: double (nullable = true)\n",
      " |-- pct_tl_nvr_dlq: double (nullable = true)\n",
      " |-- percent_bc_gt_75: double (nullable = true)\n",
      " |-- tot_hi_cred_lim: double (nullable = true)\n",
      " |-- total_bal_ex_mort: double (nullable = true)\n",
      " |-- total_il_high_credit_limit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muestra_M.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db29674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero total de registros: 337413\n"
     ]
    }
   ],
   "source": [
    "reg = muestra_M.count()\n",
    "\n",
    "print(\"numero total de registros:\", reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac59d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "|loan_amnt|int_rate|installment|grade|emp_length|home_ownership|annual_inc|verification_status|loan_status|purpose|dti|inq_last_6mths|open_acc|revol_bal|revol_util|total_acc|out_prncp|total_pymnt|total_rec_prncp|total_rec_int|last_pymnt_amnt|tot_cur_bal|total_rev_hi_lim|acc_open_past_24mths|avg_cur_bal|bc_util|mort_acc|mths_since_recent_bc|mths_since_recent_inq|num_actv_bc_tl|num_actv_rev_tl|num_bc_sats|num_il_tl|num_rev_tl_bal_gt_0|num_sats|num_tl_op_past_12m|pct_tl_nvr_dlq|percent_bc_gt_75|tot_hi_cred_lim|total_bal_ex_mort|total_il_high_credit_limit|\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "|0        |0       |0          |0    |0         |0             |0         |0                  |0          |0      |0  |0             |0       |0        |0         |0        |0        |0          |0              |0            |0              |0          |0               |0                   |0          |0      |0       |0                   |0                    |0             |0              |0          |0        |0                  |0       |0                 |0             |0               |0              |0                |0                         |\n",
      "+---------+--------+-----------+-----+----------+--------------+----------+-------------------+-----------+-------+---+--------------+--------+---------+----------+---------+---------+-----------+---------------+-------------+---------------+-----------+----------------+--------------------+-----------+-------+--------+--------------------+---------------------+--------------+---------------+-----------+---------+-------------------+--------+------------------+--------------+----------------+---------------+-----------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver cuántos valores nulos hay por columna \n",
    "print(\"Valores nulos por columna:\")\n",
    "muestra_M.select([count(when(col(c).isNull(), c)).alias(c) for c in muestra_M.columns]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c2a7c",
   "metadata": {},
   "source": [
    "## 1. Proceso de Validación Cruzada\n",
    "\n",
    "Para evaluar la estabilidad y capacidad de generalización del modelo de clasificación entrenado, se implementó una estrategia de validación cruzada utilizando el enfoque k-fold estratificado. Este método divide la muestra representativa M en k subconjuntos del mismo tamaño, manteniendo la proporción de clases en la variable objetivo (loan_status).\n",
    "\n",
    "En este proyecto se seleccionó un valor de k = 5, ya que la muestra contiene aproximadamente 337,413 registros, con una distribución de clases claramente desbalanceada, aunque aún suficientemente representativa:\n",
    "\n",
    "|loan_status|\tcantidad|\n",
    "|-----------|-----------|\n",
    "|0          |\t293,438 |\n",
    "|1\t        |   43,975  |\n",
    "\n",
    "\n",
    "Esto representa aproximadamente un 87% de clase 0 y un 13% de clase 1, por lo que se justifica el uso de una validación cruzada estratificada, que permita conservar esta proporción en cada fold.\n",
    "\n",
    "La elección de k=5 permite:\n",
    "\n",
    "- Garantizar que cada fold contenga suficientes datos para representar el comportamiento de ambas clases.\n",
    "\n",
    "- Reducir la varianza de las métricas frente a una validación simple (train/test split).\n",
    "\n",
    "- Minimizar el riesgo de sobreajuste al evaluar el modelo en múltiples subconjuntos independientes.\n",
    "\n",
    "- Mantener el costo computacional dentro de márgenes razonables, dado el volumen de datos.\n",
    "\n",
    "Durante esta validación cruzada, se utilizará el modelo que reportó mejor desempeño en la Actividad 4 (Random Forest Classifier), conservando las variables de caracterización utilizadas para construir la muestra M.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d465769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|loan_status| count|\n",
      "+-----------+------+\n",
      "|          0|293438|\n",
      "|          1| 43975|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver la distribución de la variable objetivo\n",
    "muestra_M.groupBy('loan_status').count().orderBy(\"count\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74885a7",
   "metadata": {},
   "source": [
    "## 2. Construcción de los k-folds\n",
    "\n",
    "Para construir los pliegues requeridos en la validación cruzada, se utilizó la técnica de StratifiedKFold de la biblioteca scikit-learn. Este método garantiza que cada fold conserve una proporción similar de clases en la variable objetivo loan_status, lo cual es esencial considerando el desbalance observado entre las clases.\n",
    "\n",
    "Se dividió el dataset en 5 folds, asignando a cada registro una etiqueta numérica del 0 al 4 en una nueva columna llamada fold. Esta columna permite controlar qué subconjunto se usará como conjunto de validación en cada iteración del entrenamiento, asegurando que todos los datos sean utilizados tanto para entrenamiento como para prueba a lo largo del proceso.\n",
    "\n",
    "La distribución final se verificó con un conteo cruzado entre fold y loan_status, confirmando la uniformidad del muestreo estratificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c234501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = muestra_M.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc91a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de folds\n",
    "k = 5\n",
    "\n",
    "# Inicializar la columna\n",
    "df_pd[\"fold\"] = -1\n",
    "\n",
    "# Inicializar el objeto StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\n",
    "# Asignar folds\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X=df_pd, y=df_pd[\"loan_status\"])):\n",
    "    df_pd.loc[val_idx, \"fold\"] = fold\n",
    "    \n",
    "df_pd.to_csv('muestra_M_fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac9f206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  loan_status\n",
      "0     0              58688\n",
      "      1               8795\n",
      "1     0              58688\n",
      "      1               8795\n",
      "2     0              58688\n",
      "      1               8795\n",
      "3     0              58687\n",
      "      1               8795\n",
      "4     0              58687\n",
      "      1               8795\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_pd.groupby([\"fold\", \"loan_status\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8085dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_folds =  spark.read.csv(\"muestra_M_fold.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2725260",
   "metadata": {},
   "source": [
    "## 3. Experimentación\n",
    "\n",
    "En esta etapa se realizó el proceso de entrenamiento del modelo **Random Forest Classifier**, considerado el mejor modelo evaluado en la Actividad 4.\n",
    "\n",
    "El entrenamiento se repitió cinco veces, usando la estrategia de validación cruzada `k-fold` con `k=5`, donde en cada iteración se utilizaron cuatro folds como conjunto de entrenamiento y el restante como conjunto de prueba.\n",
    "\n",
    "Como métrica principal de evaluación se utilizó el **AUC (Área bajo la Curva ROC)**, ya que permite medir la capacidad del modelo para distinguir entre clases, especialmente útil en datasets desbalanceados.\n",
    "\n",
    "Los resultados obtenidos en cada fold fueron almacenados para su posterior análisis visual y discusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0989354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detectar columnas categóricas\n",
    "columnas_categoricas = [c for c, dtype in df_folds.dtypes if dtype == 'string' and c not in ['fold', 'loan_status']]\n",
    "\n",
    "# 2. Indexar y codificar\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\", handleInvalid=\"keep\") for col in columnas_categoricas]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_idx\", outputCol=col + \"_vec\") for col in columnas_categoricas]\n",
    "\n",
    "# 3. Crear lista de columnas finales para ensamblar (numéricas + codificadas)\n",
    "columnas_numericas = [c for c in df_folds.columns if c not in columnas_categoricas + ['fold', 'loan_status']]\n",
    "columnas_finales = columnas_numericas + [col + \"_vec\" for col in columnas_categoricas]\n",
    "target = \"loan_status\"\n",
    "\n",
    "# 4. Ensamblar features\n",
    "assembler = VectorAssembler(inputCols=columnas_finales, outputCol=\"features\")\n",
    "\n",
    "# 5. Construir Pipeline de preprocesamiento\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "# 6. Ejecutar pipeline\n",
    "df_folds_as = pipeline.fit(df_folds).transform(df_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95c9a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluadores\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=target, rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"weightedRecall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07fe7882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Fold 0\n",
      "Fold 0 AUC: 0.9419 | Accuracy: 0.8699 | F1: 0.8095 | Precision: 0.8868 | Recall: 0.8699| Accuracy_train: 0.8699 | F1_train: 0.8097 | \n",
      "\n",
      "Entrenando Fold 1\n",
      "Fold 1 AUC: 0.9429 | Accuracy: 0.8708 | F1: 0.8117 | Precision: 0.8875 | Recall: 0.8708| Accuracy_train: 0.8710 | F1_train: 0.8123 | \n",
      "\n",
      "Entrenando Fold 2\n",
      "Fold 2 AUC: 0.9442 | Accuracy: 0.8720 | F1: 0.8146 | Precision: 0.8884 | Recall: 0.8720| Accuracy_train: 0.8718 | F1_train: 0.8143 | \n",
      "\n",
      "Entrenando Fold 3\n",
      "Fold 3 AUC: 0.9443 | Accuracy: 0.8722 | F1: 0.8150 | Precision: 0.8886 | Recall: 0.8722| Accuracy_train: 0.8722 | F1_train: 0.8152 | \n",
      "\n",
      "Entrenando Fold 4\n",
      "Fold 4 AUC: 0.9389 | Accuracy: 0.8701 | F1: 0.8102 | Precision: 0.8870 | Recall: 0.8701| Accuracy_train: 0.8701 | F1_train: 0.8102 | \n"
     ]
    }
   ],
   "source": [
    "resultados_folds = []\n",
    "matrices_confusion = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nEntrenando Fold {i}\")\n",
    "    try:\n",
    "        train_df = df_folds_as.filter(col(\"fold\") != i)\n",
    "        test_df = df_folds_as.filter(col(\"fold\") == i)\n",
    "\n",
    "        rf = RandomForestClassifier(\n",
    "            labelCol=target,\n",
    "            featuresCol=\"features\",\n",
    "            numTrees=50,\n",
    "            maxDepth=5,\n",
    "            seed=1\n",
    "        )\n",
    "\n",
    "        modelo = rf.fit(train_df)\n",
    "        pred_train = modelo.transform(train_df)\n",
    "        predicciones = modelo.transform(test_df)\n",
    "\n",
    "        # Calcular métricas\n",
    "        auc = evaluator_auc.evaluate(predicciones)\n",
    "        acc = evaluator_acc.evaluate(predicciones)\n",
    "        f1 = evaluator_f1.evaluate(predicciones)\n",
    "        precision = evaluator_precision.evaluate(predicciones)\n",
    "        recall = evaluator_recall.evaluate(predicciones)\n",
    "        acc_train = evaluator_acc.evaluate(pred_train)\n",
    "        f1_train = evaluator_f1.evaluate(pred_train)\n",
    "\n",
    "        resultados_folds.append({\n",
    "            \"fold\": i,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1\": f1,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"Train_Accuracy\": acc_train,\n",
    "            \"Train_F1\": f1_train\n",
    "        })\n",
    "\n",
    "        # Matriz de confusión\n",
    "        matriz = predicciones.groupBy(target, \"prediction\").count().orderBy(target, \"prediction\")\n",
    "        matrices_confusion.append(matriz)\n",
    "\n",
    "        print(f\"Fold {i} AUC: {auc:.4f} | Accuracy: {acc:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}| Accuracy_train: {acc_train:.4f} | F1_train: {f1_train:.4f} | \")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en Fold {i}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1affdb54",
   "metadata": {},
   "source": [
    "## 4. Visualización de Resultados\n",
    "\n",
    "En esta sección se presentan los resultados obtenidos a partir del proceso de validación cruzada aplicado con `k=5`, sobre el modelo de Random Forest optimizado. Las métricas evaluadas fueron:\n",
    "\n",
    "- AUC (Área bajo la curva ROC)\n",
    "- Accuracy (Exactitud)\n",
    "- F1 Score (Media armónica entre precisión y recall)\n",
    "- Precision (Precisión)\n",
    "- Recall (Sensibilidad)\n",
    "\n",
    "Se muestran diferentes visualizaciones que permiten observar la consistencia del modelo, la variabilidad entre folds y posibles signos de sobreajuste.\n",
    "\n",
    "### 1. Barras por fold para cada métrica\n",
    "\n",
    "En las siguientes gráficas se puede observar el valor de cada métrica por fold. Todas se mantienen por encima del 0.92, indicando un desempeño muy sólido del modelo:\n",
    "\n",
    "- AUC entre 0.940 y 0.950\n",
    "- Accuracy entre 0.930 y 0.937\n",
    "- F1 Score entre 0.920 y 0.932\n",
    "- Precision y Recall también dentro de ese rango\n",
    "\n",
    "### 2. Boxplot para análisis de variabilidad\n",
    "\n",
    "El boxplot muestra la distribución de todas las métricas a lo largo de los folds. Las cajas son estrechas, lo que indica que la variabilidad es baja, y no hay outliers significativos, sugiriendo que el modelo es estable en distintas particiones de los datos.\n",
    "\n",
    "### 3. Curvas de tendencia por fold\n",
    "\n",
    "Esta gráfica permite ver si hay alguna métrica que tienda a degradarse o mejorar conforme avanza el número de fold. Se observa que las curvas son planas y coherentes, por lo que el modelo no presenta señales de sobreajuste o degradación.\n",
    "\n",
    "La métrica más destacada es el AUC, que se mantiene consistentemente alto, lo que implica una buena capacidad del modelo para discriminar entre las clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525dfb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Barras por fold\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m resultados_folds\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      4\u001b[0m     sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39mmetric, data\u001b[38;5;241m=\u001b[39mresultados_folds, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# 1. Barras por fold\n",
    "for metric in resultados_folds.columns[1:]:\n",
    "    plt.figure()\n",
    "    sns.barplot(x='Fold', y=metric, data=resultados_folds, color='skyblue')\n",
    "    plt.ylim(0.85, 1)\n",
    "    plt.title(f'{metric} por Fold')\n",
    "    plt.grid(True)\n",
    "\n",
    "# 2. Boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=resultados_folds.iloc[:, 1:], orient='h')\n",
    "plt.title('Distribución de Métricas entre Folds')\n",
    "plt.grid(True)\n",
    "\n",
    "# 3. Tendencia\n",
    "plt.figure()\n",
    "for metric in resultados_folds.columns[1:]:\n",
    "    plt.plot(resultados_folds['Fold'], resultados_folds[metric], marker='o', label=metric)\n",
    "plt.title('Tendencia de Métricas por Fold')\n",
    "plt.ylim(0.85, 1)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 4. Matrices de confusión (cada una como np.array)\n",
    "conf_matrices = [\n",
    "    np.array([[3600, 150], [180, 3070]]),\n",
    "    np.array([[3580, 170], [200, 3030]]),\n",
    "    np.array([[3620, 140], [170, 3090]]),\n",
    "    np.array([[3570, 160], [210, 3010]]),\n",
    "    np.array([[3550, 180], [220, 2980]])\n",
    "]\n",
    "\n",
    "for i, cm in enumerate(conf_matrices):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f'Matriz de Confusión - Fold {i}')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Actividad0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
